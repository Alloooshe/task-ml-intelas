{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, pipeline\n",
    "from custom_dataset import LedgerDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'testing.xlsx'\n",
    "save_json_name ='test.json'\n",
    "model_name = \"output_base_3/checkpoint-10000/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(file_name, sheet_name=None, index_col=None)\n",
    "df = pd.concat(df.values(),ignore_index=True)\n",
    "target_column = \"target\"\n",
    "source_column = \"source\"\n",
    "\n",
    "df = df.rename(columns={\"Intelas Ledger Name\": target_column, \"Source Ledger Name\": source_column})\n",
    "df_to_save = df.apply(lambda x: {'id':str(x.name), 'translation': {'source' : x[source_column], 'target' : x[target_column]} }, axis=1)\n",
    "with open(save_json_name, 'w') as fout:\n",
    "    json.dump(list(df_to_save.to_dict().values()) , fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "translator = pipeline(\"translation_source_to_target\", model=model_name,max_length=30)\n",
    "test_dataset = LedgerDataset(save_json_name,tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"translate source to target: \"\n",
    "res = []\n",
    "for item in test_dataset : \n",
    "    text = prefix + item[\"translation\"][\"source\"]\n",
    "    target_text = item[\"translation\"][\"target\"]\n",
    "    pred = translator(text)[0]['translation_text']\n",
    "    res.append({\n",
    "        \"text\":text, \n",
    "        \"target\" : target_text,\n",
    "        \"pred\" : pred, \n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets =[x[\"target\"] for x in res]\n",
    "predictions = [x[\"pred\"] for x in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum =0 \n",
    "failed= 0 \n",
    "for i in range(len(targets)): \n",
    "    if targets[i] == predictions[i]:\n",
    "        sum+=1\n",
    "    else : \n",
    "        failed +=1 \n",
    "        print(f\"target : {targets[i]}\\n prediction : {predictions[i]}\")\n",
    "print(\"accuracy : \")\n",
    "print(sum/len(targets))\n",
    "print(failed/len(targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_recall_fscore_support(np.array(targets), np.array(predictions), average='weighted')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4884395e646e0a375baeb8d9c0cde3d28b17c210e29da863a0ad1228d6d7b91f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
